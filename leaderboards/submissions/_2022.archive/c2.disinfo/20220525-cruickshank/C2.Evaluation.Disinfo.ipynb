{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbbb6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# PhoMemes 2022 Evaluation Script\n",
    "#  - For Disinformation Challenge Evaluation\n",
    "#\n",
    "# Used to evaluate PhoMeme challenge submission for\n",
    "#  for \n",
    "# --------------------------------------------------\n",
    "version = 1.0 # Notebook Version Number\n",
    "edition = \"c2\"\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408b8580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "863e6e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f50f160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63892d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runtag': '1.1',\n",
       " 'date': '2022-05-25',\n",
       " 'organization': 'CMU-CASOS',\n",
       " 'model_description': 'Visual embeddings combined with supervised learning on user distribution features of their visual embeddings.',\n",
       " 'type': 'automatic',\n",
       " 'paper': 'https://github.com/ijcruic/PhoMemes2022-Submission',\n",
       " 'code': 'https://github.com/ijcruic/PhoMemes2022-Submission'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info = None\n",
    "with open(\"metadata.json\", \"r\") as in_file:\n",
    "    model_info = json.load(in_file)\n",
    "    \n",
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790842a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d792cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_df = pd.read_csv(\"../../../data/c2.disinfo/groundtruth.csv\", index_col=\"user_id\")\n",
    "run_df = pd.read_csv(\"run.csv\", index_col=\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1824cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "866d68e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = run_df.join(groundtruth_df, how=\"inner\", lsuffix=\"_pred\", rsuffix=\"_truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc8998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdaada9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 411\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "MISSING",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bb04cec946b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MISSING\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: MISSING"
     ]
    }
   ],
   "source": [
    "missing = set(groundtruth_df.index).difference(joined_df.index)\n",
    "print(\"Missing:\", len(missing))\n",
    "\n",
    "if len(missing) > 0:\n",
    "    raise Exception(\"MISSING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f999a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authentic</th>\n",
       "      <th>campaign</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00089fde8c02ff8682194c07e1feba12-22748</th>\n",
       "      <td>0</td>\n",
       "      <td>campaign.iranian_2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003a3149a530c30fc087a3c6a1569f64-2614</th>\n",
       "      <td>0</td>\n",
       "      <td>campaign.russia_2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003a4f66e267e8ccfacd07a197c35b72-8870</th>\n",
       "      <td>0</td>\n",
       "      <td>campaign.venezuela_2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00502fc7175a80a670d3a26879a37bad-6177</th>\n",
       "      <td>0</td>\n",
       "      <td>campaign.china_2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>008be68978727b3bfb55f6e18dde046d-51962</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff6590876f45c76cf24135a20b408697-22705</th>\n",
       "      <td>0</td>\n",
       "      <td>campaign.iranian_2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff88be354761f97bf509a011bf54562a-46589</th>\n",
       "      <td>0</td>\n",
       "      <td>campaign.china_2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff8f4d72f3c03218dd4b4e74b2d40ac1-6053</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff90f04ffe4d1c826248232328756555-41656</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffa9390888a211456d0296d3a8dfe81e-23380</th>\n",
       "      <td>0</td>\n",
       "      <td>campaign.china_2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2095 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        authentic                 campaign\n",
       "user_id                                                                   \n",
       "00089fde8c02ff8682194c07e1feba12-22748          0    campaign.iranian_2018\n",
       "003a3149a530c30fc087a3c6a1569f64-2614           0     campaign.russia_2018\n",
       "003a4f66e267e8ccfacd07a197c35b72-8870           0  campaign.venezuela_2019\n",
       "00502fc7175a80a670d3a26879a37bad-6177           0      campaign.china_2019\n",
       "008be68978727b3bfb55f6e18dde046d-51962          1                     None\n",
       "...                                           ...                      ...\n",
       "ff6590876f45c76cf24135a20b408697-22705          0    campaign.iranian_2018\n",
       "ff88be354761f97bf509a011bf54562a-46589          0      campaign.china_2019\n",
       "ff8f4d72f3c03218dd4b4e74b2d40ac1-6053           1                     None\n",
       "ff90f04ffe4d1c826248232328756555-41656          1                     None\n",
       "ffa9390888a211456d0296d3a8dfe81e-23380          0      campaign.china_2019\n",
       "\n",
       "[2095 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3323c510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['authentic_pred', 'campaign_pred', 'authentic_truth', 'campaign_truth'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a54bb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disinfo_agent_prediction = [True if a == 0 else False for a in joined_df[\"authentic_pred\"]]\n",
    "disinfo_agent_truth = [True if a == 0 else False for a in joined_df[\"authentic_truth\"]]\n",
    "\n",
    "ac_score_overall = accuracy_score(disinfo_agent_prediction, disinfo_agent_truth)\n",
    "pr_score_overall = precision_score(disinfo_agent_prediction, disinfo_agent_truth)\n",
    "rc_score_overall = recall_score(disinfo_agent_prediction, disinfo_agent_truth)\n",
    "\n",
    "f1_score_overall = f1_score(disinfo_agent_prediction, disinfo_agent_truth, zero_division=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d982b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "211a9aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7465393794749403\n",
      "Precision: 0.701255230125523\n",
      "Recall: 0.8280632411067194\n",
      "F1: 0.7594019030357951\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", ac_score_overall)\n",
    "print(\"Precision:\", pr_score_overall)\n",
    "print(\"Recall:\", rc_score_overall)\n",
    "print(\"F1:\", f1_score_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8897ed27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79ce6d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 900\n",
      "[None] Ac: 0.7465393794749403\n",
      "[None] Pr: 0.8066666666666666\n",
      "[None] Rc: 0.6703601108033241\n",
      "[None] F1: 0.7322239031770046\n",
      "********************\n",
      "campaign.venezuela_2019 382\n",
      "[campaign.venezuela_2019] Ac: 0.8391408114558473\n",
      "[campaign.venezuela_2019] Pr: 0.35340314136125656\n",
      "[campaign.venezuela_2019] Rc: 0.6\n",
      "[campaign.venezuela_2019] F1: 0.4448105436573312\n",
      "********************\n",
      "campaign.iranian_2018 327\n",
      "[campaign.iranian_2018] Ac: 0.7933174224343675\n",
      "[campaign.iranian_2018] Pr: 0.40978593272171254\n",
      "[campaign.iranian_2018] Rc: 0.3582887700534759\n",
      "[campaign.iranian_2018] F1: 0.38231098430813126\n",
      "********************\n",
      "campaign.russia_2018 285\n",
      "[campaign.russia_2018] Ac: 0.8176610978520287\n",
      "[campaign.russia_2018] Pr: 0.3684210526315789\n",
      "[campaign.russia_2018] Rc: 0.34201954397394135\n",
      "[campaign.russia_2018] F1: 0.3547297297297297\n",
      "********************\n",
      "campaign.china_2019 201\n",
      "[campaign.china_2019] Ac: 0.9155131264916467\n",
      "[campaign.china_2019] Pr: 0.32338308457711445\n",
      "[campaign.china_2019] Rc: 0.6132075471698113\n",
      "[campaign.china_2019] F1: 0.42345276872964177\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "acs = []\n",
    "prs = []\n",
    "rcs = []\n",
    "f1s = []\n",
    "\n",
    "for i,j in joined_df[\"campaign_truth\"].value_counts().items():\n",
    "    print(i,j)\n",
    "    \n",
    "    this_pred = joined_df['campaign_pred'] == i\n",
    "    this_true = joined_df['campaign_truth'] == i\n",
    "    \n",
    "    ac_score_this = accuracy_score(this_pred, this_true)\n",
    "    acs.append(ac_score_this)\n",
    "    \n",
    "    pr_score_this = precision_score(this_pred, this_true, zero_division=0)\n",
    "    prs.append(pr_score_this)\n",
    "    \n",
    "    rc_score_this = recall_score(this_pred, this_true, zero_division=0)\n",
    "    rcs.append(rc_score_this)\n",
    "    \n",
    "    f1_score_this = f1_score(this_pred, this_true, zero_division=0)\n",
    "    f1s.append(f1_score_this)\n",
    "    \n",
    "    print(\"[%s] Ac:\" % i, ac_score_this)\n",
    "    print(\"[%s] Pr:\" % i, pr_score_this)\n",
    "    print(\"[%s] Rc:\" % i, rc_score_this)\n",
    "    print(\"[%s] F1:\" % i, f1_score_this)\n",
    "    \n",
    "    print(\"*\" * 20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177760f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17f8bf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-Average Ac: 0.822434367541766\n",
      "Macro-Average Pr: 0.4523319755916659\n",
      "Macro-Average Rc: 0.5167751944001105\n",
      "Macro-Average F1: 0.46750558592036773\n"
     ]
    }
   ],
   "source": [
    "ac_mean = np.mean(acs)\n",
    "pr_mean = np.mean(prs)\n",
    "rc_mean = np.mean(rcs)\n",
    "f1_mean = np.mean(f1s)\n",
    "\n",
    "print(\"Macro-Average Ac:\", ac_mean)\n",
    "print(\"Macro-Average Pr:\", pr_mean)\n",
    "print(\"Macro-Average Rc:\", rc_mean)\n",
    "print(\"Macro-Average F1:\", f1_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76002a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a999c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organization</th>\n",
       "      <th>model_description</th>\n",
       "      <th>type</th>\n",
       "      <th>paper</th>\n",
       "      <th>code</th>\n",
       "      <th>accuracy_overall</th>\n",
       "      <th>precision_overall</th>\n",
       "      <th>recall_overall</th>\n",
       "      <th>f1_overall</th>\n",
       "      <th>accuracy_macro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>runtag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CMU-CASOS-1.1-2022-05-25</th>\n",
       "      <td>CMU-CASOS</td>\n",
       "      <td>Visual embeddings combined with supervised lea...</td>\n",
       "      <td>automatic</td>\n",
       "      <td>https://github.com/ijcruic/PhoMemes2022-Submis...</td>\n",
       "      <td>https://github.com/ijcruic/PhoMemes2022-Submis...</td>\n",
       "      <td>0.746539</td>\n",
       "      <td>0.701255</td>\n",
       "      <td>0.828063</td>\n",
       "      <td>0.759402</td>\n",
       "      <td>0.822434</td>\n",
       "      <td>0.452332</td>\n",
       "      <td>0.516775</td>\n",
       "      <td>0.467506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         organization  \\\n",
       "runtag                                  \n",
       "CMU-CASOS-1.1-2022-05-25    CMU-CASOS   \n",
       "\n",
       "                                                          model_description  \\\n",
       "runtag                                                                        \n",
       "CMU-CASOS-1.1-2022-05-25  Visual embeddings combined with supervised lea...   \n",
       "\n",
       "                               type  \\\n",
       "runtag                                \n",
       "CMU-CASOS-1.1-2022-05-25  automatic   \n",
       "\n",
       "                                                                      paper  \\\n",
       "runtag                                                                        \n",
       "CMU-CASOS-1.1-2022-05-25  https://github.com/ijcruic/PhoMemes2022-Submis...   \n",
       "\n",
       "                                                                       code  \\\n",
       "runtag                                                                        \n",
       "CMU-CASOS-1.1-2022-05-25  https://github.com/ijcruic/PhoMemes2022-Submis...   \n",
       "\n",
       "                          accuracy_overall  precision_overall  recall_overall  \\\n",
       "runtag                                                                          \n",
       "CMU-CASOS-1.1-2022-05-25          0.746539           0.701255        0.828063   \n",
       "\n",
       "                          f1_overall  accuracy_macro  precision_macro  \\\n",
       "runtag                                                                  \n",
       "CMU-CASOS-1.1-2022-05-25    0.759402        0.822434         0.452332   \n",
       "\n",
       "                          recall_macro  f1_macro  \n",
       "runtag                                            \n",
       "CMU-CASOS-1.1-2022-05-25      0.516775  0.467506  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = [{\n",
    "    \"runtag\": \"%s-%s-%s\" % (model_info[\"organization\"], model_info[\"runtag\"], model_info[\"date\"]),\n",
    "    \"organization\": model_info[\"organization\"],\n",
    "    \"model_description\": model_info[\"model_description\"],\n",
    "    \"type\": model_info[\"type\"],\n",
    "    \"paper\": model_info[\"paper\"],\n",
    "    \"code\": model_info[\"code\"],\n",
    "    \"accuracy_overall\": ac_score_overall,\n",
    "    \"precision_overall\": pr_score_overall,\n",
    "    \"recall_overall\": rc_score_overall,\n",
    "    \"f1_overall\": f1_score_overall,\n",
    "    \"accuracy_macro\": ac_mean,\n",
    "    \"precision_macro\": pr_mean,\n",
    "    \"recall_macro\": rc_mean,\n",
    "    \"f1_macro\": f1_mean,\n",
    "}]\n",
    "\n",
    "leaderboard_df = pd.DataFrame(rows).set_index(\"runtag\")\n",
    "leaderboard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74440688",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaderboard_df.to_csv(\"leaderboard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a63a10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
