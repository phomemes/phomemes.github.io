{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3439bb3",
   "metadata": {},
   "source": [
    "# Combine Pickled Embeddings and Image ID CSVs\n",
    "\n",
    "__Date__: 21 March 2023\n",
    "\n",
    "__Description__: The PhoMemes 2023 Challenge 2 on screenshots requires creating a run-file CSV that maps image IDs to a label of whether that image contains a screenshot or not. Here, we provide scaffolding for how to join the provided embedding files and the CSV indices files for each actor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f28d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a589e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff86b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, download the encoded_pickle_indices.tgz archive, which contains CSV\n",
    "#. files for every actor in the testing dataset. Each row of the CSV contains an index\n",
    "#. and an image ID, so you can map the row of that actor's embedding matrix to a specific image\n",
    "# This file is available in Google drive\n",
    "#. https://drive.google.com/file/d/1a_7OMeSXe8I7U2PfTd6KAgQIQp4sC_xy/view?usp=share_link\n",
    "embedding_indices_path = \"encoded_pickle_indices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a1f6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde02f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now download all 16 of the `*.partition.tar` files from Google Drive.\n",
    "#. Each partiiton contains separate hashed accounts and pickle files containing\n",
    "#. matrices of dense embeddings, where each row corresponds to a particular image.\n",
    "\n",
    "# These files are available in Google Drive:\n",
    "#. https://drive.google.com/drive/folders/1h8kNnNwN31NPuA-j-6aWih5WSZGU687q?usp=share_link\n",
    "for f in glob.iglob(\"sample_embeddings/*-effnet1.pickle\"):\n",
    "    \n",
    "    # get the User ID\n",
    "    user_id = f.partition(\"/\")[-1].partition(\"-\")[0]\n",
    "\n",
    "    # Match user ID to a CSV in the encoded pickle indices\n",
    "    this_index_path = os.path.join(embedding_indices_path, user_id + \".csv\")\n",
    "    this_index_df = pd.read_csv(this_index_path, index_col=\"index\")\n",
    "    \n",
    "    # Load the dense embeddings\n",
    "    this_user_embeddings = None\n",
    "    with open(f, \"rb\") as in_file:\n",
    "        this_user_embeddings = pickle.load(in_file)\n",
    "        \n",
    "    # Now join embeddings and image IDs, leaving a dataframe with image IDs and their embeddings\n",
    "    this_user_embeddings_df = pd.DataFrame(this_user_embeddings, index=this_index_df[\"img_id\"])\n",
    "    \n",
    "    # Do whatever processing here or accumulate all users' embeddings\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f218d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
